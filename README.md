<img src="https://flagcdn.com/w40/us.png" alt="English" width="30"/> English
<br>

<h3>ğŸ’ CART (Classification and Regression Trees) Implementation</h3>
This project demonstrates a comprehensive implementation of a Classification and Regression Tree (CART) model using Python's scikit-learn library. The purpose is to walk through the complete machine learning pipeline, from data preparation to model optimization and interpretation.

ğŸš€ Project Goal
The primary goal is to build, evaluate, and optimize a decision tree model for a classification task, using various industry-standard techniques to ensure robust performance and to prevent overfitting.

ğŸ“Š Dataset Used

Data Source: A user-provided CSV file.

Content: A dataset for a classification problem where the target variable is named Outcome.

ğŸ§  Model and Methodology

Data Preparation: The dataset is loaded, and the features (X) are separated from the target variable (y).

Baseline Model: A basic DecisionTreeClassifier is trained on the entire dataset to establish a performance benchmark.

Model Evaluation:

Holdout Method: The data is split into training and testing sets to evaluate the model's out-of-sample performance.

Cross-Validation: The model is evaluated using 5-fold cross-validation with multiple scoring metrics (accuracy, f1, roc_auc).

Hyperparameter Optimization: A GridSearchCV approach is used to systematically search for the best combination of hyperparameters, specifically max_depth and min_samples_split, to find the optimal model.

Final Model: The model is retrained with the best hyperparameters found during the grid search and then evaluated again using cross-validation.

Model Interpretation:

Feature Importance: A bar plot visualizes the importance of each feature in the final model's decision-making process.

Decision Tree Visualization: The final decision tree is plotted to provide a visual representation of the decision rules.

Decision Rules Extraction: The textual rules of the decision tree are extracted and printed.

Validation Curve (Bonus): A validation curve is plotted to analyze the model's performance on both training and validation sets as a single hyperparameter is varied, helping to diagnose bias-variance tradeoffs.

âœ¨ Results

Hyperparameter Tuning:

Best Parameters: {'max_depth': 4, 'min_samples_split': 11}

Best CV Score: ~0.76 (e.g., ROC AUC)

Final Model Performance (Cross-Validation):

Final CV Accuracy: ~0.77

Final CV F1: ~0.67

Final CV ROC AUC: ~0.83

These results demonstrate the successful optimization of the CART model, leading to improved predictive performance and providing a clear understanding of the model's decision process.

<br><br><br>

<img src="https://flagcdn.com/w40/tr.png" alt="Turkish" width="30"/> TÃ¼rkÃ§e
<br>

<h3>ğŸ’ CART (SÄ±nÄ±flandÄ±rma ve Regresyon AÄŸaÃ§larÄ±) UygulamasÄ±</h3>
Bu proje, Python'Ä±n scikit-learn kÃ¼tÃ¼phanesini kullanarak kapsamlÄ± bir SÄ±nÄ±flandÄ±rma ve Regresyon AÄŸacÄ± (CART) modelinin uygulamasÄ±nÄ± gÃ¶stermektedir. AmacÄ±, veri hazÄ±rlÄ±ÄŸÄ±ndan model optimizasyonuna ve yorumlamaya kadar eksiksiz bir makine Ã¶ÄŸrenimi sÃ¼recini adÄ±m adÄ±m anlatmaktÄ±r.

ğŸš€ Proje AmacÄ±
Temel amaÃ§, doÄŸru performansÄ± saÄŸlamak ve aÅŸÄ±rÄ± Ã¶ÄŸrenmeyi (overfitting) Ã¶nlemek iÃ§in Ã§eÅŸitli standart teknikleri kullanarak bir sÄ±nÄ±flandÄ±rma gÃ¶revi iÃ§in bir karar aÄŸacÄ± modelini oluÅŸturmak, deÄŸerlendirmek ve optimize etmektir.

ğŸ“Š KullanÄ±lan Veri Seti

Veri KaynaÄŸÄ±: KullanÄ±cÄ± tarafÄ±ndan saÄŸlanan bir CSV dosyasÄ±.

Ä°Ã§erik: Hedef deÄŸiÅŸkeni Outcome olarak adlandÄ±rÄ±lan bir sÄ±nÄ±flandÄ±rma problemi iÃ§in bir veri seti.

ğŸ§  Model ve YÃ¶ntem

Veri HazÄ±rlÄ±ÄŸÄ±: Veri seti yÃ¼klenir, Ã¶zellikler (X) hedef deÄŸiÅŸkenden (y) ayrÄ±lÄ±r.

Temel Model: Performans iÃ§in bir baÅŸlangÄ±Ã§ noktasÄ± oluÅŸturmak Ã¼zere tÃ¼m veri seti Ã¼zerinde temel bir DecisionTreeClassifier modeli eÄŸitilir.

Model DeÄŸerlendirme:

Holdout YÃ¶ntemi: Modelin test verilerindeki performansÄ±nÄ± deÄŸerlendirmek iÃ§in veri, eÄŸitim ve test setlerine ayrÄ±lÄ±r.

Ã‡apraz DoÄŸrulama (Cross-Validation): Model, accuracy, f1 ve roc_auc gibi birden fazla metrik kullanÄ±larak 5 katlÄ± Ã§apraz doÄŸrulama ile deÄŸerlendirilir.

Hiperparametre Optimizasyonu: Modelin en uygun performansÄ±nÄ± bulmak iÃ§in Ã¶zellikle max_depth ve min_samples_split hiperparametreleri iÃ§in sistematik bir arama yapan GridSearchCV yaklaÅŸÄ±mÄ± kullanÄ±lÄ±r.

Final Model: En iyi performansÄ± gÃ¶steren hiperparametreler kullanÄ±larak model yeniden eÄŸitilir ve Ã§apraz doÄŸrulama ile tekrar deÄŸerlendirilir.

Model Yorumlama:

Ã–zellik Ã–nem GrafiÄŸi: Son modelin karar verme sÃ¼recindeki her bir Ã¶zelliÄŸin Ã¶nemini gÃ¶steren bir Ã§ubuk grafik gÃ¶rselleÅŸtirilir.

Karar AÄŸacÄ± GÃ¶rselleÅŸtirme: Karar kurallarÄ±nÄ± gÃ¶rsel olarak temsil etmek iÃ§in nihai karar aÄŸacÄ± Ã§izilir.

Karar KurallarÄ± Ã‡Ä±karma: Karar aÄŸacÄ±nÄ±n metinsel kurallarÄ± Ã§Ä±karÄ±larak yazdÄ±rÄ±lÄ±r.

DoÄŸrulama EÄŸrisi (BONUS): Modelin tek bir hiperparametre deÄŸiÅŸtikÃ§e hem eÄŸitim hem de doÄŸrulama setlerindeki performansÄ±nÄ± analiz etmek ve sapma-varyans dengesini teÅŸhis etmek iÃ§in bir doÄŸrulama eÄŸrisi Ã§izilir.

âœ¨ SonuÃ§lar

Hiperparametre Optimizasyonu:

En Ä°yi Parametreler: {'max_depth': 4, 'min_samples_split': 11}

En Ä°yi CV Skoru: ~0.76 (Ã¶rn: ROC AUC)

Final Model PerformansÄ± (Ã‡apraz DoÄŸrulama):

Final CV Accuracy: ~0.77

Final CV F1: ~0.67

Final CV ROC AUC: ~0.83

Bu sonuÃ§lar, CART modelinin baÅŸarÄ±lÄ± bir ÅŸekilde optimize edildiÄŸini, geliÅŸmiÅŸ tahmin performansÄ± saÄŸladÄ±ÄŸÄ±nÄ± ve modelin karar verme sÃ¼recini net bir ÅŸekilde anlama imkanÄ± sunduÄŸunu gÃ¶stermektedir.
